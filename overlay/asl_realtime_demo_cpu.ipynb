{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b4cee-b60c-4792-bc3d-076db87842c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Real-time ASL demo on a laptop:\n",
    "- Captures frames from the built-in webcam.\n",
    "- Extracts a hand region of interest (ROI) and preprocesses to 28x28.\n",
    "- Runs the full ASL CNN on the CPU.\n",
    "- Overlays the predicted ASL letter on the video stream and shows the ROI box.\n",
    "\n",
    "Designed for a short demo video with signs: D, I, E, U, and an \"unknown\" open-hand.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from time import perf_counter\n",
    "\n",
    "# -----------------------------\n",
    "# CNN and labels\n",
    "# -----------------------------\n",
    "IMG_H, IMG_W, IMG_C = 28, 28, 1\n",
    "\n",
    "# Label mapping (adapt to your training label order)\n",
    "ASL_CLASSES = [\n",
    "    'A','B','C','D','E','F','G','H','I','K',\n",
    "    'L','M','N','O','P','Q','R','S','T','U',\n",
    "    'V','W','X','Y'\n",
    "]\n",
    "UNKNOWN_LABEL = 'UNK'\n",
    "\n",
    "print(\"Loading full ASL CNN model...\")\n",
    "model = tf.keras.models.load_model(\"asl_cnn_full.h5\")\n",
    "print(\"Model loaded.\")\n",
    "# Optional: model.summary()\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: classify one ROI\n",
    "# -----------------------------\n",
    "\n",
    "def classify_roi(gray_roi):\n",
    "    \"\"\"\n",
    "    gray_roi: 2D uint8 image (cropped hand), arbitrary size.\n",
    "    Returns (pred_label, pred_prob, latency_ms).\n",
    "    \"\"\"\n",
    "    # Resize to 28x28 and normalize\n",
    "    roi_resized = cv2.resize(gray_roi, (IMG_W, IMG_H),\n",
    "                             interpolation=cv2.INTER_AREA)\n",
    "    roi_norm = roi_resized.astype(np.float32) / 255.0\n",
    "    roi_norm = roi_norm.reshape(1, IMG_H, IMG_W, IMG_C)\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    logits = model.predict(roi_norm, batch_size=1, verbose=0)[0]  # (25,)\n",
    "    t1 = perf_counter()\n",
    "\n",
    "    probs = tf.nn.softmax(logits).numpy()\n",
    "    pred_idx = int(np.argmax(probs))\n",
    "    pred_prob = float(probs[pred_idx])\n",
    "\n",
    "    if pred_prob < 0.6:   # rejection threshold; tune as needed\n",
    "        pred_label = UNKNOWN_LABEL\n",
    "    else:\n",
    "        pred_label = ASL_CLASSES[pred_idx]\n",
    "\n",
    "    latency_ms = (t1 - t0) * 1000.0\n",
    "    return pred_label, pred_prob, latency_ms\n",
    "\n",
    "# -----------------------------\n",
    "# Demo loop with laptop webcam\n",
    "# -----------------------------\n",
    "\n",
    "def run_demo():\n",
    "    cap = cv2.VideoCapture(0)  # default laptop webcam\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"ERROR: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    print(\"Starting ASL CPU demo. Press 'q' to quit.\")\n",
    "    frame_count = 0\n",
    "    avg_latency_ms = 0.0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Webcam read failed.\")\n",
    "            break\n",
    "\n",
    "        frame_h, frame_w = frame.shape[:2]\n",
    "\n",
    "        # --- Simple hand ROI: central square region ---\n",
    "        box_size = min(frame_w, frame_h) // 2\n",
    "        x1 = frame_w // 2 - box_size // 2\n",
    "        y1 = frame_h // 2 - box_size // 2\n",
    "        x2 = x1 + box_size\n",
    "        y2 = y1 + box_size\n",
    "\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Classify the ROI using full CPU model\n",
    "        pred_label, pred_prob, latency_ms = classify_roi(gray_roi)\n",
    "\n",
    "        # Running average latency for display\n",
    "        frame_count += 1\n",
    "        avg_latency_ms = ((avg_latency_ms * (frame_count - 1)) + latency_ms) / frame_count\n",
    "        fps = 1000.0 / avg_latency_ms if avg_latency_ms > 0 else 0.0\n",
    "\n",
    "        # --- Visual overlays ---\n",
    "\n",
    "        # ROI box\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Simple finger/hand highlighting using an Otsu mask\n",
    "        _, mask = cv2.threshold(gray_roi, 0, 255,\n",
    "                                cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        mask_colored = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "        mask_resized = cv2.resize(mask_colored, (box_size, box_size),\n",
    "                                  interpolation=cv2.INTER_NEAREST)\n",
    "        overlay_region = frame[y1:y2, x1:x2]\n",
    "        blended = cv2.addWeighted(overlay_region, 0.7, mask_resized, 0.3, 0)\n",
    "        frame[y1:y2, x1:x2] = blended\n",
    "\n",
    "        # Prediction text\n",
    "        text = f\"Pred: {pred_label} ({pred_prob*100:.1f}%), {latency_ms:.1f} ms\"\n",
    "        cv2.putText(frame, text, (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "\n",
    "        # Average latency / FPS\n",
    "        stats = f\"Avg latency: {avg_latency_ms:.1f} ms  ({fps:.1f} FPS)\"\n",
    "        cv2.putText(frame, stats, (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"ASL CPU Demo\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (lung38)",
   "language": "python",
   "name": "lung38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
